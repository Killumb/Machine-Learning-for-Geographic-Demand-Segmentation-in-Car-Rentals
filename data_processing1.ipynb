{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bb81f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Начало Этапа 2: Предобработка данных ---\n",
      "✅ Исходный датасет 'CarRentalDataV1.csv' успешно загружен. Размер: (5851, 16)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ЭТАП 2: Подготовка данных и инжиниринг признаков\n",
    "# ===================================================================\n",
    "\n",
    "# Импортируем pandas для работы с таблицами и datetime для работы с датами\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"--- Начало Этапа 2: Предобработка данных ---\")\n",
    "\n",
    "# Загружаем исходный датасет. \n",
    "# На этом этапе мы работаем с \"сырыми\" данными, загруженными после EDA.\n",
    "try:\n",
    "    df = pd.read_csv('CarRentalDataV1.csv')\n",
    "    print(f\"✅ Исходный датасет 'CarRentalDataV1.csv' успешно загружен. Размер: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Ошибка: Файл 'CarRentalDataV1.csv' не найден.\")\n",
    "    # Прерываем выполнение, если основной файл отсутствует\n",
    "    # В ноутбуке можно просто остановить выполнение ячейки\n",
    "\n",
    "# Создаем копию датафрейма для всех преобразований, чтобы не изменять исходный df\n",
    "df_processed = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e482b5a",
   "metadata": {},
   "source": [
    "### Шаг 2.1: Очистка данных (Data Cleaning)\n",
    "\n",
    "На этом шаге мы приводим данные в порядок:\n",
    "1.  **Обрабатываем пропущенные значения (NaN):**\n",
    "    - Для числовых счетчиков (`rating`, `reviewCount`, `renterTripsTaken`) предполагаем, что пропуск означает отсутствие данных (например, у новой машины нет поездок), поэтому заменяем их на `0`.\n",
    "    - Для категориальных признаков (`fuelType`, `vehicle.type`) заменяем редкие пропуски самым частым значением (модой).\n",
    "2.  **Исправляем типы данных:** Идентификаторы и счетчики преобразуем в целочисленный тип (`int`).\n",
    "3.  **Удаляем ненужные столбцы:** `location.country` (везде 'US') и `airportcity` (часто дублирует `location.city`) не несут уникальной информации для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55649c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в числовых счетчиках заменены на 0.\n",
      "Пропуски в категориальных признаках заменены модой.\n",
      "Типы данных для id, trips и reviews исправлены на integer.\n",
      "Колонки ['location.country', 'airportcity'] удалены.\n",
      "\n",
      "✅ Очистка данных завершена.\n",
      "Размер датасета после очистки: (5851, 14)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Обработка пропущенных значений ---\n",
    "for col in ['rating', 'reviewCount', 'renterTripsTaken']:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        df_processed[col] = df_processed[col].fillna(0)\n",
    "print(\"Пропуски в числовых счетчиках заменены на 0.\")\n",
    "\n",
    "for col in ['fuelType', 'vehicle.type', 'location.city', 'location.state']:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        mode_value = df_processed[col].mode()[0]\n",
    "        df_processed[col] = df_processed[col].fillna(mode_value)\n",
    "print(\"Пропуски в категориальных признаках заменены модой.\")\n",
    "\n",
    "# --- 2. Исправление типов данных ---\n",
    "df_processed['owner.id'] = df_processed['owner.id'].astype(int)\n",
    "df_processed['renterTripsTaken'] = df_processed['renterTripsTaken'].astype(int)\n",
    "df_processed['reviewCount'] = df_processed['reviewCount'].astype(int)\n",
    "print(\"Типы данных для id, trips и reviews исправлены на integer.\")\n",
    "\n",
    "# --- 3. Удаление ненужных столбцов и дубликатов ---\n",
    "columns_to_drop = ['location.country', 'airportcity']\n",
    "df_processed = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"Колонки {columns_to_drop} удалены.\")\n",
    "\n",
    "if df_processed.duplicated().sum() > 0:\n",
    "    df_processed = df_processed.drop_duplicates(inplace=True)\n",
    "    print(f\"Удалено {df_processed.duplicated().sum()} дублирующихся строк.\")\n",
    "\n",
    "print(\"\\n✅ Очистка данных завершена.\")\n",
    "print(f\"Размер датасета после очистки: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e7b59",
   "metadata": {},
   "source": [
    "### Шаг 2.2: Инжиниринг признаков (Feature Engineering)\n",
    "\n",
    "Это самый творческий и важный шаг подготовки. Мы создаем новые, более информативные признаки, которые помогут модели лучше понять \"контекст\" каждой машины.\n",
    "1.  **`vehicle.age`**: Возраст автомобиля. Интуитивно понятно, что год выпуска влияет на спрос.\n",
    "2.  **Агрегированные признаки:** Для каждого автомобиля мы вычисляем характеристики рынка, на котором он находится:\n",
    "    - `city_avg_trips`: Средний спрос в городе.\n",
    "    - `city_car_count`: Уровень конкуренции в городе.\n",
    "    - `city_avg_rate`: Средний уровень цен в городе.\n",
    "    \n",
    "Эти \"контекстуальные\" признаки являются очень мощными предикторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1900758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Создание новых признаков ---\n",
      "Создан признак 'vehicle.age'.\n",
      "Созданы и присоединены агрегированные признаки по городу и штату.\n",
      "\n",
      "✅ Инжиниринг признаков завершен.\n",
      "Пример данных с новыми признаками:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "renterTripsTaken",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "vehicle.age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "city_avg_trips",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "city_car_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "61961b32-e51e-4cae-9748-1aca9da8ec12",
       "rows": [
        [
         "0",
         "13",
         "4.0",
         "78.11764705882354",
         "15"
        ],
        [
         "1",
         "2",
         "5.0",
         "2.0",
         "1"
        ],
        [
         "2",
         "28",
         "11.0",
         "19.045454545454547",
         "18"
        ],
        [
         "3",
         "21",
         "5.0",
         "19.045454545454547",
         "18"
        ],
        [
         "4",
         "3",
         "13.0",
         "19.045454545454547",
         "18"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>renterTripsTaken</th>\n",
       "      <th>vehicle.age</th>\n",
       "      <th>city_avg_trips</th>\n",
       "      <th>city_car_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78.117647</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.045455</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.045455</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.045455</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   renterTripsTaken  vehicle.age  city_avg_trips  city_car_count\n",
       "0                13          4.0       78.117647              15\n",
       "1                 2          5.0        2.000000               1\n",
       "2                28         11.0       19.045455              18\n",
       "3                21          5.0       19.045455              18\n",
       "4                 3         13.0       19.045455              18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Создание новых признаков ---\")\n",
    "\n",
    "# --- 1. Создание признака \"Возраст автомобиля\" ---\n",
    "current_year = 2023 # Используем фиксированный год для воспроизводимости\n",
    "df_processed['vehicle.age'] = current_year - df_processed['vehicle.year']\n",
    "# Удаляем возможные аномалии (машины из будущего)\n",
    "df_processed = df_processed[df_processed['vehicle.age'] >= 0]\n",
    "print(\"Создан признак 'vehicle.age'.\")\n",
    "\n",
    "# --- 2. Создание агрегированных признаков по географии ---\n",
    "# Сначала считаем статистики по каждому городу и штату\n",
    "city_stats = df_processed.groupby('location.city').agg(\n",
    "    city_avg_trips=('renterTripsTaken', 'mean'),\n",
    "    city_car_count=('owner.id', 'nunique'),\n",
    "    city_avg_rate=('rate.daily', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "state_stats = df_processed.groupby('location.state').agg(\n",
    "    state_avg_trips=('renterTripsTaken', 'mean'),\n",
    "    state_car_count=('owner.id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Теперь присоединяем эти статистики к основному датафрейму\n",
    "df_processed = pd.merge(df_processed, city_stats, on='location.city', how='left')\n",
    "df_processed = pd.merge(df_processed, state_stats, on='location.state', how='left')\n",
    "print(\"Созданы и присоединены агрегированные признаки по городу и штату.\")\n",
    "\n",
    "print(\"\\n✅ Инжиниринг признаков завершен.\")\n",
    "print(\"Пример данных с новыми признаками:\")\n",
    "display(df_processed[['renterTripsTaken', 'vehicle.age', 'city_avg_trips', 'city_car_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06257afb",
   "metadata": {},
   "source": [
    "### Шаг 2.3 и 2.4: Кодирование, разделение и сохранение\n",
    "\n",
    "Последние шаги перед моделированием:\n",
    "1.  **Выбор признаков:** Отбираем столбцы, которые будем использовать для обучения.\n",
    "2.  **Кодирование категорий:** Преобразуем текстовые признаки (`fuelType`, `vehicle.type`) в числовой формат с помощью **One-Hot Encoding**.\n",
    "3.  **Разделение выборки:** Делим данные на обучающую (`train`) и тестовую (`test`) части.\n",
    "4.  **Сохранение результатов:** Сохраняем подготовленные датасеты в `.csv` файлы. Это лучшая практика, которая делает наш проект модульным и избавляет от проблем с переменными на следующих этапах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e874bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Подготовка финального датафрейма для модели ---\n",
      "Данные закодированы и готовы к разделению.\n",
      "Данные разделены на обучающую и тестовую выборки.\n",
      "\n",
      "✅ Все подготовленные датасеты сохранены в папку 'processed_data'.\n",
      "Размер X_train: (4680, 16), Размер X_test: (1171, 16)\n",
      "\n",
      "--- Этап 2 полностью завершен. ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Выбор признаков и кодирование ---\n",
    "print(\"\\n--- Подготовка финального датафрейма для модели ---\")\n",
    "target = 'renterTripsTaken'\n",
    "numerical_features = [\n",
    "    'rating', 'reviewCount', 'rate.daily', 'vehicle.age',\n",
    "    'city_avg_trips', 'city_car_count', 'city_avg_rate',\n",
    "    'state_avg_trips', 'state_car_count'\n",
    "]\n",
    "categorical_features = ['fuelType', 'vehicle.type']\n",
    "\n",
    "# Создаем датафрейм только с нужными колонками\n",
    "model_df = df_processed[numerical_features + categorical_features + [target]].copy()\n",
    "\n",
    "# Применяем One-Hot Encoding\n",
    "model_df = pd.get_dummies(model_df, columns=categorical_features, prefix=categorical_features, drop_first=True)\n",
    "\n",
    "# Обработка возможных пропусков после merge (например, для новых городов, которых не было в train)\n",
    "if model_df.isnull().sum().sum() > 0:\n",
    "    model_df = model_df.fillna(model_df.median())\n",
    "print(\"Данные закодированы и готовы к разделению.\")\n",
    "\n",
    "# --- 2. Разделение данных ---\n",
    "X = model_df.drop(columns=[target])\n",
    "y = model_df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Данные разделены на обучающую и тестовую выборки.\")\n",
    "\n",
    "# --- 3. Сохранение результатов на диск ---\n",
    "output_dir = 'processed_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Сохраняем все подготовленные части\n",
    "X_train.to_csv(os.path.join(output_dir, 'X_train.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(output_dir, 'X_test.csv'), index=False)\n",
    "y_train.to_csv(os.path.join(output_dir, 'y_train.csv'), index=False)\n",
    "y_test.to_csv(os.path.join(output_dir, 'y_test.csv'), index=False)\n",
    "# Сохраняем полный model_df для гибкости на этапе 3\n",
    "model_df.to_csv(os.path.join(output_dir, 'model_df.csv'), index=False)\n",
    "# Сохраняем city_stats, он понадобится для этапа 4\n",
    "city_stats.to_csv(os.path.join(output_dir, 'city_stats.csv'), index=False)\n",
    "\n",
    "print(f\"\\n✅ Все подготовленные датасеты сохранены в папку '{output_dir}'.\")\n",
    "print(f\"Размер X_train: {X_train.shape}, Размер X_test: {X_test.shape}\")\n",
    "print(\"\\n--- Этап 2 полностью завершен. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2360672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рассчитанные пороги спроса:\n",
      "{'average_demand': np.float64(15.0), 'high_demand': np.float64(30.52777777777778)}\n",
      "\n",
      "✅ Пороги успешно сохранены в файл 'processed_data/demand_thresholds.json'.\n"
     ]
    }
   ],
   "source": [
    "# --- Расчет порогов для бизнес-логики ---\n",
    "\n",
    "\n",
    "demand_thresholds = {\n",
    "    \"average_demand\": city_stats['city_avg_trips'].quantile(0.50),\n",
    "    \"high_demand\": city_stats['city_avg_trips'].quantile(0.75)\n",
    "}\n",
    "\n",
    "print(\"Рассчитанные пороги спроса:\")\n",
    "print(demand_thresholds)\n",
    "\n",
    "# Сохраняем пороги в простой текстовый файл (json)\n",
    "import json\n",
    "output_dir = 'processed_data' # Убедитесь, что эта папка существует\n",
    "with open(os.path.join(output_dir, 'demand_thresholds.json'), 'w') as f:\n",
    "    json.dump(demand_thresholds, f)\n",
    "\n",
    "print(f\"\\n✅ Пороги успешно сохранены в файл '{output_dir}/demand_thresholds.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
